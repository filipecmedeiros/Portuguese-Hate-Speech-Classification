{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d55cdd24-9990-4922-b545-fd0dd1cd8e00",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c66dc2-d651-4465-9654-4ba5ac5e9244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import InputLayer, Dense, Dropout, Conv1D, GlobalMaxPooling1D, MaxPooling2D, Flatten, Embedding, Activation, LSTM\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027afa11-eca7-4583-a371-d1019a994d66",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a1d48e-5f34-497b-a9f0-572119b12a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/hsd_pre_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a10b906-55de-4a1c-b5ed-8ee0d6586997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>hatespeech_comb</th>\n",
       "      <th>hatespeech_G1</th>\n",
       "      <th>annotator_G1</th>\n",
       "      <th>hatespeech_G2</th>\n",
       "      <th>annotator_G2</th>\n",
       "      <th>hatespeech_G3</th>\n",
       "      <th>annotator_G3</th>\n",
       "      <th>pre_processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@__andrea__b \\nO cara vive em outro mundo\\nNão...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>cara vive outro mundo mundo real refugiados vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@_carmeloneto Estes incompetentes não cuidam n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>incompetentes cuidam povo brasileiro poucos re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@_carmeloneto \\nOs 'cumpanhero' quebraram toda...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>cumpanhero quebraram toda regras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@_GlitteryKisses é isso não conseguem pensar n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>conseguem pensar sentido lato além vê frente o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@_iglira bom dia macaco branco haha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>bom dia macaco branco haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665</th>\n",
       "      <td>5665</td>\n",
       "      <td>@zecarlosantos2 é o unico que nao se corrompe....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>unico nao corrompenao vende chega aroporto apl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>5666</td>\n",
       "      <td>@zqkitowz sei das cotas, mas não sabia disso, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>sei cotas sabia disso putaria porra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>5667</td>\n",
       "      <td>@zqkitowz sim, a maioria do eleitorado é mulhe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>sim maioria eleitorado mulher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>5668</td>\n",
       "      <td>@zurcju seguir no tt é facíl, apresentar as am...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>seguir tt facíl apresentar amigas sapatão ngm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>5669</td>\n",
       "      <td>na vdd a culpa é do menino de 11 anos otário q...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>vdd culpa menino ano otário chamava burragorda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5670 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "0              0  @__andrea__b \\nO cara vive em outro mundo\\nNão...   \n",
       "1              1  @_carmeloneto Estes incompetentes não cuidam n...   \n",
       "2              2  @_carmeloneto \\nOs 'cumpanhero' quebraram toda...   \n",
       "3              3  @_GlitteryKisses é isso não conseguem pensar n...   \n",
       "4              4                @_iglira bom dia macaco branco haha   \n",
       "...          ...                                                ...   \n",
       "5665        5665  @zecarlosantos2 é o unico que nao se corrompe....   \n",
       "5666        5666  @zqkitowz sei das cotas, mas não sabia disso, ...   \n",
       "5667        5667  @zqkitowz sim, a maioria do eleitorado é mulhe...   \n",
       "5668        5668  @zurcju seguir no tt é facíl, apresentar as am...   \n",
       "5669        5669  na vdd a culpa é do menino de 11 anos otário q...   \n",
       "\n",
       "      hatespeech_comb  hatespeech_G1 annotator_G1  hatespeech_G2 annotator_G2  \\\n",
       "0                   1              1            A            1.0            V   \n",
       "1                   0              1            D            0.0            V   \n",
       "2                   0              1            A            0.0            B   \n",
       "3                   0              0            C            0.0            V   \n",
       "4                   1              0            A            1.0            I   \n",
       "...               ...            ...          ...            ...          ...   \n",
       "5665                0              1            C            0.0            B   \n",
       "5666                1              1            D            1.0           It   \n",
       "5667                0              0            C            0.0            V   \n",
       "5668                1              1            C            1.0            S   \n",
       "5669                1              1            E            1.0           It   \n",
       "\n",
       "      hatespeech_G3 annotator_G3  \\\n",
       "0                 0            E   \n",
       "1                 0            C   \n",
       "2                 0            E   \n",
       "3                 0            D   \n",
       "4                 1            E   \n",
       "...             ...          ...   \n",
       "5665              0            A   \n",
       "5666              0            A   \n",
       "5667              0            C   \n",
       "5668              0            A   \n",
       "5669              0            D   \n",
       "\n",
       "                                     pre_processed_text  \n",
       "0     cara vive outro mundo mundo real refugiados vi...  \n",
       "1     incompetentes cuidam povo brasileiro poucos re...  \n",
       "2                      cumpanhero quebraram toda regras  \n",
       "3     conseguem pensar sentido lato além vê frente o...  \n",
       "4                            bom dia macaco branco haha  \n",
       "...                                                 ...  \n",
       "5665  unico nao corrompenao vende chega aroporto apl...  \n",
       "5666                sei cotas sabia disso putaria porra  \n",
       "5667                      sim maioria eleitorado mulher  \n",
       "5668  seguir tt facíl apresentar amigas sapatão ngm ...  \n",
       "5669  vdd culpa menino ano otário chamava burragorda...  \n",
       "\n",
       "[5670 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c238de8c-97dc-476b-801b-a2f7ce683a81",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3aa301-c558-42a4-93a7-6ff08ffb977d",
   "metadata": {},
   "source": [
    "## CHI-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1954e3-1ae2-47a7-82a4-5b3e798309c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['pre_processed_text']\n",
    "y = df['hatespeech_comb']\n",
    "\n",
    "\n",
    "def feature_selection_chi2(X,y):\n",
    "  normalizer = MinMaxScaler()\n",
    "  X_norm = normalizer.fit_transform(X)\n",
    "  chi_selector = SelectKBest(chi2, k=241)\n",
    "  chi_selector.fit(X_norm, y)\n",
    "\n",
    "  chi_support = chi_selector.get_support()\n",
    "  selected_features = np.where(chi_support)[0]\n",
    "  #chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "  #print(str(len(selected_features)), 'selected features')\n",
    "  return selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9920db4a-b921-4306-900d-1e1121031ea6",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0750e4c5-367f-40c7-9cac-74c761034890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(X_train, X_test, n_grams):\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, n_grams))\n",
    "    X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "    X_test = vectorizer.transform(X_test).toarray()\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7dd0b-303b-438a-b90d-83a419a0f806",
   "metadata": {},
   "source": [
    "# Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1591290-f83d-4841-8f5a-d52c8be845a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['pre_processed_text']\n",
    "y = df['hatespeech_comb']\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Hold out\n",
    "sss = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, train_size = 0.8, random_state = RANDOM_STATE)\n",
    "for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b092b63-c48c-411e-a370-aa8c0f7eb306",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e829dbc6-3734-49d5-998c-56fb1d5dd0a1",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "183feadf-af87-454a-8620-26de8982fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74cc5292-47a4-40bf-bca9-49a52c4fe32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_func = 'relu'\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "max_len = 50000\n",
    "vocab_size = 2000  # Total number of words in the vocabulary\n",
    "embedding_dim = 100  # Embedding dimension\n",
    "lstm_units = 50  # Number of units in the LSTM layer\n",
    "\n",
    "def lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(shape=(max_len,)))\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(lstm_units, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    adam = Adam(learning_rate=learning_rate, clipvalue=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['binary_accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5623017-0049-43ee-bb84-1d61f14b41ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Training\n",
      "Folder :0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50000\u001b[0m, \u001b[38;5;34m100\u001b[0m)     │       \u001b[38;5;34m200,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50000\u001b[0m, \u001b[38;5;34m100\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m30,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">230,251</span> (899.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m230,251\u001b[0m (899.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">230,251</span> (899.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m230,251\u001b[0m (899.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m 3/29\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31:44\u001b[0m 73s/step - binary_accuracy: 0.6376 - loss: 0.6825"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, train_size=0.8, random_state=42)\n",
    "\n",
    "results = []\n",
    "f1 = []\n",
    "accuracy = []\n",
    "\n",
    "X = df['pre_processed_text']\n",
    "y = df['hatespeech_comb']\n",
    "n_gram = 2\n",
    "\n",
    "print(\"# Training\")\n",
    "\n",
    "for i, (train_index_cv, val_index) in enumerate(sss.split(X_train, y_train)):\n",
    "    print(f\"Folder :{i}\")\n",
    "    X_train_cv, X_val = X[train_index_cv], X[val_index]\n",
    "    y_train_cv, y_val = y[train_index_cv], y[val_index]\n",
    "\n",
    "    # bag of words\n",
    "    X_train_cv, X_val = bag_of_words(X_train_cv, X_val, n_gram)\n",
    "\n",
    "    # Padding\n",
    "    X_train_cv = pad_sequences(X_train_cv, maxlen=max_len, padding='post')\n",
    "    X_val = pad_sequences(X_val, maxlen=max_len, padding='post')\n",
    "\n",
    "\n",
    "    # Model\n",
    "    model = KerasClassifier(model=lstm_model,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size)\n",
    "    \n",
    "    # Fit\n",
    "    model.fit(X_train_cv, y_train_cv)\n",
    "    pred = model.predict(X_val)\n",
    "\n",
    "    result = classification_report(y_val, pred)\n",
    "    results.append(result)\n",
    "\n",
    "    f = f1_score(y_val, pred)\n",
    "    f1.append(f)\n",
    "    print(f\"# F1: {f}\")\n",
    "\n",
    "    acc = accuracy_score(y_val, pred)\n",
    "    accuracy.append(acc)\n",
    "    print(f\"# Accuracy: {acc}\")\n",
    "    print(\"===============\")\n",
    "\n",
    "print(\"# Mean Accuracy: \", mean(accuracy))\n",
    "print(\"# Mean F1: \", mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bea02d-2cc3-4d55-8bb4-3534f9e84ede",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a32fd-d07d-4672-b094-8de06b7fbaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model = lstm_model,\n",
    "                        epochs = epochs,\n",
    "                        batch_size = batch_size)\n",
    "\n",
    "\n",
    "X_train, X_test = bag_of_words(X_train, X_test, n_gram)\n",
    "\n",
    "\n",
    "# Padding\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding='post')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "result = classification_report(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
