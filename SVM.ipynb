{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d971f2-cef1-4a7d-8283-f01c1ba4c3ac",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8656a8-ec79-475e-91ce-bf9e43f5f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c15a9-26d1-4b30-915a-1ed0d08d4cdf",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7a1bb4-e489-4682-a61a-035b8ca8d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_processed_text = 'gemini_embedding'\n",
    "# pre_processed_text = 'text_embed'\n",
    "pre_processed_text = 'pre_processed_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40c956c-cbbf-4a94-93e0-337c01649753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/hsd_pre_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "906cc9ff-ad9e-4bd9-955e-c7722006f639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hatespeech_comb</th>\n",
       "      <th>hatespeech_G1</th>\n",
       "      <th>annotator_G1</th>\n",
       "      <th>hatespeech_G2</th>\n",
       "      <th>annotator_G2</th>\n",
       "      <th>hatespeech_G3</th>\n",
       "      <th>annotator_G3</th>\n",
       "      <th>pre_processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@__andrea__b \\nO cara vive em outro mundo\\nNão...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>cara vive outro mundo mundo real refugiados vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@_carmeloneto Estes incompetentes não cuidam n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>incompetentes cuidam povo brasileiro poucos re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@_carmeloneto \\nOs 'cumpanhero' quebraram toda...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>cumpanhero quebraram toda regras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@_GlitteryKisses é isso não conseguem pensar n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>conseguem pensar sentido lato além vê frente o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@_iglira bom dia macaco branco haha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>bom dia macaco branco haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665</th>\n",
       "      <td>@zecarlosantos2 é o unico que nao se corrompe....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>unico nao corrompenao vende chega aroporto apl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>@zqkitowz sei das cotas, mas não sabia disso, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>sei cotas sabia disso putaria porra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>@zqkitowz sim, a maioria do eleitorado é mulhe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>sim maioria eleitorado mulher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>@zurcju seguir no tt é facíl, apresentar as am...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>seguir tt facíl apresentar amigas sapatão ngm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>na vdd a culpa é do menino de 11 anos otário q...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>vdd culpa menino ano otário chamava burragorda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5670 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  hatespeech_comb  \\\n",
       "0     @__andrea__b \\nO cara vive em outro mundo\\nNão...                1   \n",
       "1     @_carmeloneto Estes incompetentes não cuidam n...                0   \n",
       "2     @_carmeloneto \\nOs 'cumpanhero' quebraram toda...                0   \n",
       "3     @_GlitteryKisses é isso não conseguem pensar n...                0   \n",
       "4                   @_iglira bom dia macaco branco haha                1   \n",
       "...                                                 ...              ...   \n",
       "5665  @zecarlosantos2 é o unico que nao se corrompe....                0   \n",
       "5666  @zqkitowz sei das cotas, mas não sabia disso, ...                1   \n",
       "5667  @zqkitowz sim, a maioria do eleitorado é mulhe...                0   \n",
       "5668  @zurcju seguir no tt é facíl, apresentar as am...                1   \n",
       "5669  na vdd a culpa é do menino de 11 anos otário q...                1   \n",
       "\n",
       "      hatespeech_G1 annotator_G1  hatespeech_G2 annotator_G2  hatespeech_G3  \\\n",
       "0                 1            A            1.0            V              0   \n",
       "1                 1            D            0.0            V              0   \n",
       "2                 1            A            0.0            B              0   \n",
       "3                 0            C            0.0            V              0   \n",
       "4                 0            A            1.0            I              1   \n",
       "...             ...          ...            ...          ...            ...   \n",
       "5665              1            C            0.0            B              0   \n",
       "5666              1            D            1.0           It              0   \n",
       "5667              0            C            0.0            V              0   \n",
       "5668              1            C            1.0            S              0   \n",
       "5669              1            E            1.0           It              0   \n",
       "\n",
       "     annotator_G3                                 pre_processed_text  \n",
       "0               E  cara vive outro mundo mundo real refugiados vi...  \n",
       "1               C  incompetentes cuidam povo brasileiro poucos re...  \n",
       "2               E                   cumpanhero quebraram toda regras  \n",
       "3               D  conseguem pensar sentido lato além vê frente o...  \n",
       "4               E                         bom dia macaco branco haha  \n",
       "...           ...                                                ...  \n",
       "5665            A  unico nao corrompenao vende chega aroporto apl...  \n",
       "5666            A                sei cotas sabia disso putaria porra  \n",
       "5667            C                      sim maioria eleitorado mulher  \n",
       "5668            A  seguir tt facíl apresentar amigas sapatão ngm ...  \n",
       "5669            D  vdd culpa menino ano otário chamava burragorda...  \n",
       "\n",
       "[5670 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be36832-3771-42fb-93a3-136b4a8bf199",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b857a8-858f-4574-91c8-175b1f8fb509",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2dc04f-e60f-4cdf-9c56-6bd0e5fe751c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1193514it [00:11, 102314.67it/s]\n"
     ]
    }
   ],
   "source": [
    "GLOVE_MODEL_FILE = './dataset/glove.twitter.27B/glove.twitter.27B.100d.txt'\n",
    "max_len = 128\n",
    "embedding_dim = 100\n",
    "\n",
    "# Tokenize\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(df['pre_processed_text'])\n",
    "seq = token.texts_to_sequences(df['pre_processed_text'])\n",
    "\n",
    "# Padding\n",
    "pad_seq = pad_sequences(seq,maxlen=embedding_dim)\n",
    "\n",
    "# Vocab size\n",
    "vocab_size = len(token.word_index)+1\n",
    "\n",
    "# Load embedding vector\n",
    "embedding_vector = {}\n",
    "f = open(GLOVE_MODEL_FILE)\n",
    "for line in tqdm(f):\n",
    "    value = line.split(' ')\n",
    "    word = value[0]\n",
    "    coef = np.array(value[1:],dtype = 'float32')\n",
    "    embedding_vector[word] = coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1396738b-9145-4ab5-a878-84fde174175f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15340/15340 [00:00<00:00, 610987.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Keep a out of vocabullary dict\n",
    "oov_dict = {}\n",
    "\n",
    "# Generate embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size,embedding_dim))\n",
    "for word,i in tqdm(token.word_index.items()):\n",
    "    embedding_value = embedding_vector.get(word)\n",
    "    if embedding_value is not None:\n",
    "        embedding_matrix[i] = embedding_value\n",
    "    else:\n",
    "        oov_dict[word] = np.random.uniform(-1., 1., (embedding_dim,)) # Generate new random vector\n",
    "        embedding_matrix[i] = oov_dict[word]\n",
    "\n",
    "\n",
    "# Transform text into embed vector\n",
    "embedded_sequences = np.zeros((len(pad_seq), max_len, embedding_dim))\n",
    "for i, seq in enumerate(pad_seq):\n",
    "    for j, idx in enumerate(seq):\n",
    "        if idx > 0:  # Skip padding index\n",
    "            embedded_sequences[i, j] = embedding_matrix[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8124054-fa0b-4d9c-bef6-311f3ca51e4b",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "520a519a-94cb-45ee-bbcd-57558fd7df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(X_train, X_test, n_grams):\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, n_grams))\n",
    "    X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "    X_test = vectorizer.transform(X_test).toarray()\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a59960-2778-4906-97c4-87f3b3c9d908",
   "metadata": {},
   "source": [
    "## CHI-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e57e51a4-2016-44e8-8536-ea9c4350a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[pre_processed_text]\n",
    "y = df['hatespeech_comb']\n",
    "\n",
    "\n",
    "def feature_selection_chi2(X,y):\n",
    "  normalizer = MinMaxScaler()\n",
    "  X_norm = normalizer.fit_transform(X)\n",
    "  chi_selector = SelectKBest(chi2, k=241)\n",
    "  chi_selector.fit(X_norm, y)\n",
    "\n",
    "  chi_support = chi_selector.get_support()\n",
    "  selected_features = np.where(chi_support)[0]\n",
    "  #chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "  #print(str(len(selected_features)), 'selected features')\n",
    "  return selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb822fe2-6140-4e42-bdeb-d8b36c7a6d38",
   "metadata": {},
   "source": [
    "# Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "390298a7-ee48-4d48-a98b-d1315903823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df[pre_processed_text]\n",
    "X = embedded_sequences\n",
    "y = df['hatespeech_comb']\n",
    "\n",
    "# Flatten\n",
    "X = np.array([matrix.ravel() for matrix in X])\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Hold out\n",
    "sss = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, train_size = 0.8, random_state = RANDOM_STATE)\n",
    "for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f88c6a2-7c54-413a-8ffc-b6969f22d6bd",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf041e6-3850-45ae-aaad-5be37c46f1af",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c9f4e81-bcaa-4966-87da-90303bacf35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Performing Grid Search\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best Parameters: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Best Model: SVC(C=100, gamma='auto')\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size = 0.2, train_size = 0.8, random_state = 42)\n",
    "model = svm.SVC(kernel='linear')\n",
    "\n",
    "results = []\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "accuracy = []\n",
    "\n",
    "\n",
    "n_gram = 2\n",
    "\n",
    "\n",
    "# Define the model and parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],   # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],  # Kernel types\n",
    "    'gamma': ['scale', 'auto']    # Kernel coefficient\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm.SVC(),\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',  # Metric for evaluation\n",
    "    cv=sss,\n",
    "    verbose=1,  # Shows progress of the grid search\n",
    "    n_jobs=-1  # Parallelize computations\n",
    ")\n",
    "\n",
    "print(\"# Performing Grid Search\")\n",
    "grid_search.fit(pd.DataFrame(X_train.tolist()), y_train)\n",
    "\n",
    "# Best parameters and model after Grid Search\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "score = grid_search.score(pd.DataFrame(X_train.tolist()), y_train)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Model:\", best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8b5cb-ca43-4677-b21e-2b75942e3c46",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1df6a95-faf7-4a8f-9cee-e61a9dfa9fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81       776\n",
      "           1       0.58      0.46      0.51       358\n",
      "\n",
      "    accuracy                           0.73      1134\n",
      "   macro avg       0.68      0.65      0.66      1134\n",
      "weighted avg       0.71      0.73      0.72      1134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel='rbf', gamma='auto', C=100)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "result = classification_report(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
