{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d971f2-cef1-4a7d-8283-f01c1ba4c3ac",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8656a8-ec79-475e-91ce-bf9e43f5f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c15a9-26d1-4b30-915a-1ed0d08d4cdf",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c40c956c-cbbf-4a94-93e0-337c01649753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/hsd_pre_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906cc9ff-ad9e-4bd9-955e-c7722006f639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>hatespeech_comb</th>\n",
       "      <th>hatespeech_G1</th>\n",
       "      <th>annotator_G1</th>\n",
       "      <th>hatespeech_G2</th>\n",
       "      <th>annotator_G2</th>\n",
       "      <th>hatespeech_G3</th>\n",
       "      <th>annotator_G3</th>\n",
       "      <th>pre_processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@__andrea__b \\nO cara vive em outro mundo\\nNão...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>cara vive outro mundo mundo real refugiados vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@_carmeloneto Estes incompetentes não cuidam n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>incompetentes cuidam povo brasileiro poucos re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@_carmeloneto \\nOs 'cumpanhero' quebraram toda...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>E</td>\n",
       "      <td>cumpanhero quebraram toda regras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@_GlitteryKisses é isso não conseguem pensar n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>conseguem pensar sentido lato além vê frente o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@_iglira bom dia macaco branco haha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>bom dia macaco branco haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665</th>\n",
       "      <td>5665</td>\n",
       "      <td>@zecarlosantos2 é o unico que nao se corrompe....</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>unico nao corrompenao vende chega aroporto apl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>5666</td>\n",
       "      <td>@zqkitowz sei das cotas, mas não sabia disso, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>sei cotas sabia disso putaria porra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>5667</td>\n",
       "      <td>@zqkitowz sim, a maioria do eleitorado é mulhe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>sim maioria eleitorado mulher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>5668</td>\n",
       "      <td>@zurcju seguir no tt é facíl, apresentar as am...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>seguir tt facíl apresentar amigas sapatão ngm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>5669</td>\n",
       "      <td>na vdd a culpa é do menino de 11 anos otário q...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>It</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>vdd culpa menino ano otário chamava burragorda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5670 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "0              0  @__andrea__b \\nO cara vive em outro mundo\\nNão...   \n",
       "1              1  @_carmeloneto Estes incompetentes não cuidam n...   \n",
       "2              2  @_carmeloneto \\nOs 'cumpanhero' quebraram toda...   \n",
       "3              3  @_GlitteryKisses é isso não conseguem pensar n...   \n",
       "4              4                @_iglira bom dia macaco branco haha   \n",
       "...          ...                                                ...   \n",
       "5665        5665  @zecarlosantos2 é o unico que nao se corrompe....   \n",
       "5666        5666  @zqkitowz sei das cotas, mas não sabia disso, ...   \n",
       "5667        5667  @zqkitowz sim, a maioria do eleitorado é mulhe...   \n",
       "5668        5668  @zurcju seguir no tt é facíl, apresentar as am...   \n",
       "5669        5669  na vdd a culpa é do menino de 11 anos otário q...   \n",
       "\n",
       "      hatespeech_comb  hatespeech_G1 annotator_G1  hatespeech_G2 annotator_G2  \\\n",
       "0                   1              1            A            1.0            V   \n",
       "1                   0              1            D            0.0            V   \n",
       "2                   0              1            A            0.0            B   \n",
       "3                   0              0            C            0.0            V   \n",
       "4                   1              0            A            1.0            I   \n",
       "...               ...            ...          ...            ...          ...   \n",
       "5665                0              1            C            0.0            B   \n",
       "5666                1              1            D            1.0           It   \n",
       "5667                0              0            C            0.0            V   \n",
       "5668                1              1            C            1.0            S   \n",
       "5669                1              1            E            1.0           It   \n",
       "\n",
       "      hatespeech_G3 annotator_G3  \\\n",
       "0                 0            E   \n",
       "1                 0            C   \n",
       "2                 0            E   \n",
       "3                 0            D   \n",
       "4                 1            E   \n",
       "...             ...          ...   \n",
       "5665              0            A   \n",
       "5666              0            A   \n",
       "5667              0            C   \n",
       "5668              0            A   \n",
       "5669              0            D   \n",
       "\n",
       "                                     pre_processed_text  \n",
       "0     cara vive outro mundo mundo real refugiados vi...  \n",
       "1     incompetentes cuidam povo brasileiro poucos re...  \n",
       "2                      cumpanhero quebraram toda regras  \n",
       "3     conseguem pensar sentido lato além vê frente o...  \n",
       "4                            bom dia macaco branco haha  \n",
       "...                                                 ...  \n",
       "5665  unico nao corrompenao vende chega aroporto apl...  \n",
       "5666                sei cotas sabia disso putaria porra  \n",
       "5667                      sim maioria eleitorado mulher  \n",
       "5668  seguir tt facíl apresentar amigas sapatão ngm ...  \n",
       "5669  vdd culpa menino ano otário chamava burragorda...  \n",
       "\n",
       "[5670 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be36832-3771-42fb-93a3-136b4a8bf199",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a59960-2778-4906-97c4-87f3b3c9d908",
   "metadata": {},
   "source": [
    "## CHI-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57e51a4-2016-44e8-8536-ea9c4350a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['pre_processed_text']\n",
    "y = df['hatespeech_comb']\n",
    "\n",
    "\n",
    "def feature_selection_chi2(X,y):\n",
    "  normalizer = MinMaxScaler()\n",
    "  X_norm = normalizer.fit_transform(X)\n",
    "  chi_selector = SelectKBest(chi2, k=241)\n",
    "  chi_selector.fit(X_norm, y)\n",
    "\n",
    "  chi_support = chi_selector.get_support()\n",
    "  selected_features = np.where(chi_support)[0]\n",
    "  #chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "  #print(str(len(selected_features)), 'selected features')\n",
    "  return selected_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8124054-fa0b-4d9c-bef6-311f3ca51e4b",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "520a519a-94cb-45ee-bbcd-57558fd7df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(X_train, X_test, n_grams):\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, n_grams))\n",
    "    X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "    X_test = vectorizer.transform(X_test).toarray()\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb822fe2-6140-4e42-bdeb-d8b36c7a6d38",
   "metadata": {},
   "source": [
    "# Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "390298a7-ee48-4d48-a98b-d1315903823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['pre_processed_text']\n",
    "y = df['hatespeech_comb']\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Hold out\n",
    "sss = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, train_size = 0.8, random_state = RANDOM_STATE)\n",
    "for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f88c6a2-7c54-413a-8ffc-b6969f22d6bd",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf041e6-3850-45ae-aaad-5be37c46f1af",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c9f4e81-bcaa-4966-87da-90303bacf35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Training\n",
      "Folder :0\n",
      "# F1: 0.5555555555555556\n",
      "# Accuracy: 0.7709251101321586\n",
      "===============\n",
      "Folder :1\n",
      "# F1: 0.5611814345991561\n",
      "# Accuracy: 0.7709251101321586\n",
      "===============\n",
      "Folder :2\n",
      "# F1: 0.46963562753036436\n",
      "# Accuracy: 0.711453744493392\n",
      "===============\n",
      "Folder :3\n",
      "# F1: 0.5032537960954447\n",
      "# Accuracy: 0.7477973568281938\n",
      "===============\n",
      "Folder :4\n",
      "# F1: 0.521551724137931\n",
      "# Accuracy: 0.7555066079295154\n",
      "===============\n",
      "# Mean Accuracy:  0.7513215859030837\n",
      "# Mean F1:  0.5222356275836904\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size = 0.2, train_size = 0.8, random_state = 42)\n",
    "model = svm.SVC(kernel='linear')\n",
    "\n",
    "results = []\n",
    "f1 = []\n",
    "precision = []\n",
    "recall = []\n",
    "accuracy = []\n",
    "\n",
    "\n",
    "n_gram = 2\n",
    "\n",
    "\n",
    "print(\"# Training\")\n",
    "\n",
    "for i, (train_index_cv, val_index) in enumerate(sss.split(X_train, y_train)):\n",
    "    print(f\"Folder :{i}\")\n",
    "    X_train_cv, X_val = X[train_index_cv], X[val_index]\n",
    "    y_train_cv, y_val = y[train_index_cv], y[val_index]\n",
    "    \n",
    "    X_train_cv, X_val = bag_of_words(X_train_cv, X_val, n_gram)\n",
    "    selected_feature_list = feature_selection_chi2(X_train_cv, y_train_cv)\n",
    "    \n",
    "    X_train_cv = X_train_cv[:,[i for i in selected_feature_list]]\n",
    "    X_val = X_val[:,[i for i in selected_feature_list]]\n",
    "    \n",
    "    model.fit(X_train_cv, y_train_cv)\n",
    "    pred = model.predict(X_val)\n",
    "\n",
    "    result = classification_report(y_val, pred)\n",
    "    results.append(result)\n",
    "\n",
    "\n",
    "    f = f1_score(y_val, pred)\n",
    "    f1.append(f)\n",
    "    print(f\"# F1: {f}\")\n",
    "\n",
    "    acc = accuracy_score(y_val, pred)\n",
    "    accuracy.append(acc)\n",
    "    print(f\"# Accuracy: {acc}\")\n",
    "    print(\"===============\")\n",
    "\n",
    "\n",
    "print(\"# Mean Accuracy: \", mean(accuracy))\n",
    "print(\"# Mean F1: \", mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8b5cb-ca43-4677-b21e-2b75942e3c46",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1df6a95-faf7-4a8f-9cee-e61a9dfa9fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83       776\n",
      "           1       0.67      0.45      0.54       358\n",
      "\n",
      "    accuracy                           0.75      1134\n",
      "   macro avg       0.72      0.67      0.68      1134\n",
      "weighted avg       0.74      0.75      0.74      1134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel='linear')\n",
    "\n",
    "\n",
    "X_train, X_test = bag_of_words(X_train, X_test, n_gram)\n",
    "selected_feature_list = feature_selection_chi2(X_train, y_train)\n",
    "\n",
    "X_train = X_train[:,[i for i in selected_feature_list]]\n",
    "X_test = X_test[:,[i for i in selected_feature_list]]\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "result = classification_report(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
